"""
Integration tests for object list functionality.

Tests the full workflow: load list → resolve objects → verify resolution rates.
"""
import pytest
import sys
from pathlib import Path

from app.object_lists.object_list_loader import ObjectListLoader
from app.catalog.catalog_service import CatalogService


# Path to actual object lists (generated by scripts/generate_object_lists.py)
# Navigate from tests/it/ up to project root, then to data/
OBJECT_LISTS_DIR = Path(__file__).parent.parent.parent / 'data' / 'object_lists'


def lists_exist() -> bool:
    """Check if generated list files exist"""
    return (OBJECT_LISTS_DIR / 'messier_110.json').exists()


@pytest.fixture
def real_loader():
    """ObjectListLoader with real CatalogService (uses OpenNGC)"""
    catalog_service = CatalogService()
    return ObjectListLoader(
        lists_dir=OBJECT_LISTS_DIR,
        catalog_service=catalog_service
    )


@pytest.mark.skipif(not lists_exist(), reason="Object list files not generated yet")
class TestMessierListIntegration:
    """Integration tests for Messier catalog"""

    def test_load_messier_list(self, real_loader):
        """Test that Messier list loads successfully"""
        obj_list = real_loader.load_list('messier_110')

        assert obj_list.metadata.name == 'Messier Catalog'
        # Note: 109 objects (M102 is a duplicate entry)
        assert obj_list.metadata.object_count == 109
        assert len(obj_list.objects) == 109

    def test_messier_resolution_rate_above_95_percent(self, real_loader):
        """
        Quality gate: At least 95% of Messier objects must resolve.
        
        This ensures our canonical_ids match what CatalogService expects.
        """
        obj_list = real_loader.load_list('messier_110')
        result = real_loader.resolve_objects(obj_list)

        print(f"\nMessier resolution: {result.success_count}/{result.total_count}")
        if result.failures:
            print("Failures:")
            for f in result.failures:
                print(f"  - {f.name} ({f.canonical_id}): {f.reason}")

        assert result.success_rate >= 95.0, (
            f"Messier resolution rate {result.success_rate:.1f}% is below 95% threshold. "
            f"Failures: {[f.name for f in result.failures]}"
        )

    def test_messier_objects_have_valid_data(self, real_loader):
        """Test that resolved Messier objects have required fields"""
        obj_list = real_loader.load_list('messier_110')
        result = real_loader.resolve_objects(obj_list)

        # Spot check some well-known objects
        m31 = next((obj for obj in result.resolved if 'M31' in obj.name or obj.canonical_id == 'NGC0224'), None)
        assert m31 is not None, "M31 should be resolved"
        assert m31.magnitude < 10, "M31 should have reasonable magnitude"
        assert m31.ra > 0, "M31 should have RA"
        assert m31.dec > 0, "M31 should have positive Dec"


@pytest.mark.skipif(not lists_exist(), reason="Object list files not generated yet")
class TestCaldwellListIntegration:
    """Integration tests for Caldwell catalog"""

    def test_load_caldwell_list(self, real_loader):
        """Test that Caldwell list loads successfully"""
        obj_list = real_loader.load_list('caldwell_109')

        assert obj_list.metadata.name == 'Caldwell Catalog'
        # May be less than 109 if some objects missing from OpenNGC
        assert obj_list.metadata.object_count >= 100

    def test_caldwell_resolution_rate_above_95_percent(self, real_loader):
        """Quality gate: At least 95% of Caldwell objects must resolve."""
        obj_list = real_loader.load_list('caldwell_109')
        result = real_loader.resolve_objects(obj_list)

        print(f"\nCaldwell resolution: {result.success_count}/{result.total_count}")
        if result.failures:
            print("Failures:")
            for f in result.failures:
                print(f"  - {f.name} ({f.canonical_id}): {f.reason}")

        assert result.success_rate >= 95.0, (
            f"Caldwell resolution rate {result.success_rate:.1f}% is below 95% threshold. "
            f"Failures: {[f.name for f in result.failures]}"
        )


@pytest.mark.skipif(not lists_exist(), reason="Object list files not generated yet")
class TestSolarSystemListIntegration:
    """Integration tests for Solar System objects"""

    def test_load_solar_system_list(self, real_loader):
        """Test that Solar System list loads successfully"""
        obj_list = real_loader.load_list('solar_system')

        assert obj_list.metadata.name == 'Solar System'
        assert obj_list.metadata.object_count == 9

    @pytest.mark.skip(reason="Solar System resolution requires Horizons API - may be slow/unreliable")
    def test_solar_system_resolution(self, real_loader):
        """Test Solar System object resolution via Horizons"""
        obj_list = real_loader.load_list('solar_system')
        result = real_loader.resolve_objects(obj_list)

        # Solar System objects resolve via Horizons
        print(f"\nSolar System resolution: {result.success_count}/{result.total_count}")
        assert result.success_count >= 5, "At least 5 solar system objects should resolve"


@pytest.mark.skipif(not lists_exist(), reason="Object list files not generated yet")
class TestAllListsQualityGate:
    """
    Quality gate tests for all shipped object lists.
    
    These tests ensure data quality before release.
    """

    def test_all_shipped_lists_meet_resolution_threshold(self, real_loader):
        """
        Quality gate: All shipped lists must have ≥95% resolution rate.
        
        This is a critical data quality check.
        """
        lists = real_loader.get_available_lists()
        
        # Skip solar_system as it uses Horizons API
        dso_lists = [l for l in lists if 'solar' not in l.list_id.lower()]
        
        failures = []
        for list_meta in dso_lists:
            obj_list = real_loader.load_list(list_meta.list_id)
            result = real_loader.resolve_objects(obj_list)
            
            if result.success_rate < 95.0:
                failures.append(
                    f"{list_meta.name}: {result.success_rate:.1f}% "
                    f"({result.failure_count} failures)"
                )
        
        assert not failures, (
            f"Lists below 95% resolution threshold:\n" + "\n".join(failures)
        )

    def test_all_lists_have_valid_metadata(self, real_loader):
        """Test that all lists have required metadata fields"""
        lists = real_loader.get_available_lists()
        
        for list_meta in lists:
            assert list_meta.list_id, f"List missing list_id"
            assert list_meta.name, f"List {list_meta.list_id} missing name"
            assert list_meta.object_count > 0, f"List {list_meta.list_id} is empty"

    def test_no_duplicate_canonical_ids_within_list(self, real_loader):
        """Test that lists don't have duplicate objects"""
        lists = real_loader.get_available_lists()
        
        for list_meta in lists:
            obj_list = real_loader.load_list(list_meta.list_id)
            canonical_ids = [obj.canonical_id for obj in obj_list.objects]
            
            duplicates = [cid for cid in canonical_ids if canonical_ids.count(cid) > 1]
            assert not duplicates, (
                f"List {list_meta.name} has duplicate canonical_ids: {set(duplicates)}"
            )


@pytest.mark.skipif(not lists_exist(), reason="Object list files not generated yet")
class TestObjectListScoringEndToEnd:
    """
    END-TO-END SCORING TESTS: Load → Resolve → Score workflow
    
    These tests catch issues that load/resolve tests miss, like:
    - Missing classification data
    - Unknown object types
    - Invalid size handling (AngularSize vs float)
    - Strategy routing errors
    """

    @pytest.fixture
    def scoring_context(self):
        """Create minimal but valid context for scoring"""
        from app.orm.model.entities import Telescope, Eyepiece, ObservationSite
        from app.domain.model.telescope_type import TelescopeType
        from app.domain.model.light_pollution import LightPollution

        telescope = Telescope(
            name="Test Scope",
            focal_length=1000,
            aperture=200,
            focal_ratio=5.0,
            type=TelescopeType.NEWTONIAN
        )
        eyepiece = Eyepiece(
            name="Test Eyepiece",
            focal_length=10,
            apparent_field_of_view=50,
            barrel_size=1.25
        )
        observation_site = ObservationSite(
            name="Test Site",
            latitude=40.0,
            longitude=-80.0,
            light_pollution=LightPollution.BORTLE_5
        )
        return {
            'telescope': telescope,
            'eyepiece': eyepiece,
            'observation_site': observation_site
        }

    def test_messier_list_loads_resolves_and_scores(self, real_loader, scoring_context):
        """
        CRITICAL: Full workflow test for Messier catalog.
        
        This catches issues that load/resolve tests miss:
        - Classification data availability
        - Unknown object types
        - Strategy routing errors
        - AngularSize handling in scoring
        
        This test would have caught the "Unknown celestial object type: unknown" error.
        """
        from app.domain.services.observability_calculation_service import ObservabilityCalculationService
        
        # Load and resolve
        messier_list = real_loader.load_list('messier_110')
        resolution_result = real_loader.resolve_objects(messier_list)
        
        assert resolution_result.success_count > 100, (
            f"Expected >100 Messier objects resolved, got {resolution_result.success_count}"
        )
        
        # Score all resolved objects
        observability_service = ObservabilityCalculationService()
        
        try:
            scored_objects = observability_service.score_celestial_objects(
                resolution_result.resolved,
                telescope=scoring_context['telescope'],
                eyepiece=scoring_context['eyepiece'],
                observation_site=scoring_context['observation_site']
            )
        except ValueError as e:
            if "Unknown celestial object type" in str(e):
                pytest.fail(
                    f"Failed to score Messier objects: {e}\n"
                    f"This means resolved objects lack proper classification.\n"
                    f"Check: CatalogService.get_object() returns CelestialObject with classification."
                )
            raise
        
        # Verify scoring succeeded
        assert len(scored_objects) == len(resolution_result.resolved), (
            f"Expected {len(resolution_result.resolved)} scored objects, "
            f"got {len(scored_objects)}"
        )
        
        # Verify scores are in reasonable range (0-25 scale)
        for obj in scored_objects:
            assert 0.0 <= obj.observability_score.normalized_score <= 25.0, (
                f"{obj.name} has invalid score: {obj.observability_score.normalized_score}"
            )

        # Verify at least some objects scored well (not all scoring 0)
        scores = [obj.observability_score.normalized_score for obj in scored_objects]
        max_score = max(scores)
        assert max_score > 1.0, (
            f"Messier objects all have very low scores (max={max_score:.3f}). "
            f"Something is wrong with scoring logic."
        )

    def test_caldwell_list_loads_resolves_and_scores(self, real_loader, scoring_context):
        """Full workflow test for Caldwell catalog"""
        from app.domain.services.observability_calculation_service import ObservabilityCalculationService
        
        caldwell_list = real_loader.load_list('caldwell_109')
        resolution_result = real_loader.resolve_objects(caldwell_list)
        
        assert resolution_result.success_count > 100, (
            f"Expected >100 Caldwell objects resolved, got {resolution_result.success_count}"
        )
        
        observability_service = ObservabilityCalculationService()
        
        try:
            scored_objects = observability_service.score_celestial_objects(
                resolution_result.resolved,
                telescope=scoring_context['telescope'],
                eyepiece=scoring_context['eyepiece'],
                observation_site=scoring_context['observation_site']
            )
        except ValueError as e:
            if "Unknown celestial object type" in str(e):
                pytest.fail(
                    f"Failed to score Caldwell objects: {e}\n"
                    f"Objects missing classification data."
                )
            raise
        
        assert len(scored_objects) == len(resolution_result.resolved)

    def test_all_object_types_handle_size_correctly(self, real_loader, scoring_context):
        """
        Test that AngularSize objects are handled correctly in scoring.
        
        This verifies the fix for: '>=' not supported between instances 
        of 'AngularSize' and 'float'
        """
        from app.domain.services.observability_calculation_service import ObservabilityCalculationService
        
        messier_list = real_loader.load_list('messier_110')
        resolution_result = real_loader.resolve_objects(messier_list)
        
        observability_service = ObservabilityCalculationService()
        
        # This should not raise TypeError about AngularSize comparisons
        try:
            scored_objects = observability_service.score_celestial_objects(
                resolution_result.resolved,
                telescope=scoring_context['telescope'],
                eyepiece=scoring_context['eyepiece'],
                observation_site=scoring_context['observation_site']
            )
        except TypeError as e:
            if "'>=' not supported between instances of 'AngularSize'" in str(e):
                pytest.fail(
                    f"AngularSize comparison error: {e}\n"
                    f"The get_size_arcmin() helper is not being used correctly."
                )
            raise
        
        # Verify objects with various size types scored successfully
        size_types = set()
        for obj in resolution_result.resolved:
            if obj.size is not None:
                size_types.add(type(obj.size).__name__)
        
        # Should have both AngularSize and possibly others
        assert len(size_types) > 0, "No sized objects in Messier catalog"
